import { DocumentedNode, LocationSpan, MapASTNodeBase, ProfileASTNodeBase } from '@superfaceai/ast';
import { LexerTokenStream } from '../../lexer';
import { IdentifierTokenData, NewlineTokenData, OperatorTokenData, SeparatorTokenData, StringTokenData, TerminationTokens } from '../../lexer/token';
import { LexerTokenMatch, RuleResult, SyntaxRule } from '../rule';
export declare type ASTNodeBase = ProfileASTNodeBase | MapASTNodeBase;
export declare type HasLocation = {
    location: LocationSpan;
};
export declare type WithLocation<N> = N extends {
    location?: LocationSpan;
} ? {
    [k in keyof N]: WithLocation<N[k]>;
} & HasLocation : {
    [k in keyof N]: WithLocation<N[k]>;
};
export declare type CommonTerminatorToken = ';' | ',' | '\n';
declare type ArrayFirstOrLastNonNull<A extends readonly (E | undefined)[], E> = A extends [E, ...(E | undefined)[]] ? true : A extends [...(E | undefined)[], E] ? true : false;
/** Decides whether a tuple/array _definitely_ has a non-null element */
declare type ArrayHasNonNull<A extends readonly (E | undefined)[], E> = ArrayFirstOrLastNonNull<A, E> extends true ? true : A extends [E | undefined, ...infer R] ? R extends readonly (E | undefined)[] ? ArrayHasNonNull<R, E> : never : A extends [...infer R, E | undefined] ? R extends readonly (E | undefined)[] ? ArrayHasNonNull<R, E> : never : false;
export declare function computeLocationSpan<A extends (HasLocation | undefined)[]>(...nodes: A): ArrayHasNonNull<A, HasLocation> extends true ? LocationSpan : LocationSpan | undefined;
export declare function documentedNode<N extends DocumentedNode>(rule: SyntaxRule<N>): SyntaxRule<N>;
/**
 * Maps token match array into a string array of the assignment keys.
 */
export declare function mapAssignmentPath(path: (LexerTokenMatch<IdentifierTokenData> | LexerTokenMatch<StringTokenData>)[]): string[];
export declare const ASSIGNMENT_PATH_KEY: SyntaxRule<(LexerTokenMatch<StringTokenData> | LexerTokenMatch<IdentifierTokenData>)[]>;
declare type TerminatorTokenRule = SyntaxRule<LexerTokenMatch<SeparatorTokenData> | LexerTokenMatch<OperatorTokenData> | LexerTokenMatch<NewlineTokenData>>;
export declare function TERMINATOR_TOKEN_FACTORY(...terminators: TerminationTokens[]): TerminatorTokenRule;
/** Utility rule builder which expects the rule to be terminated and the optionally skips `,` or `;` */
export declare function expectTerminated<T>(rule: SyntaxRule<T>, ...terminators: TerminationTokens[]): SyntaxRule<T>;
export declare class SyntaxRuleSourceChecksum extends SyntaxRule<string> {
    tryMatch(tokens: LexerTokenStream<unknown>): RuleResult<string>;
    [Symbol.toStringTag](): string;
}
export {};
