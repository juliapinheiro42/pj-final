import { Source } from '../source';
import { LexerContext } from './context';
import { LexerToken, LexerTokenKind } from './token';
export declare type LexerTokenKindFilter = {
    [K in LexerTokenKind]: boolean;
};
export declare const DEFAULT_TOKEN_KIND_FILTER: LexerTokenKindFilter;
export interface LexerTokenStream<SavedState = unknown> extends Generator<LexerToken, undefined, LexerContext | undefined> {
    tokenKindFilter: LexerTokenKindFilter;
    readonly source: Source;
    peek(...context: [] | [LexerContext | undefined]): IteratorResult<LexerToken, undefined>;
    /** Saves the stream state to be restored later. */
    save(): SavedState;
    /** Roll back the state of the stream to the given saved state. */
    rollback(token: SavedState): void;
}
/**
 * Lexer tokenizes input string into tokens.
 *
 * The lexer generates a stream of tokens, always starting with SEPARATOR SOF and always ending with SEPARATOR EOF.
 * The stream can be consumed by calling `advance`. After each advance, `lookahead` will provide access to the next
 * token without consuming it.
 * After EOF is emitted, all further calls to `advance` and `lookahead` will return the same EOF.
 *
 * An optional `tokenKindFilter` parameter can be provided to filter
 * the tokens returned by `advance` and `lookahead`. By default, this filter skips comment nodes.
 *
 * The advance function also accepts an optional `context` parameter which can be used to control the lexer context
 * for the next token.
 */
export declare class Lexer implements LexerTokenStream<[LexerToken, boolean]> {
    readonly source: Source;
    private readonly sublexers;
    /** Last emitted token. */
    private currentToken;
    /** Stores whether the SOF and EOF were yielded. */
    private fileSeparatorYielded;
    /** Token kinds to filter from the stream. */
    tokenKindFilter: LexerTokenKindFilter;
    constructor(source: Source, tokenKindFilter?: LexerTokenKindFilter);
    /** Advances the lexer returning the current token. */
    advance(context?: LexerContext): LexerToken;
    /** Returns the next token without advancing the lexer. */
    lookahead(context?: LexerContext): LexerToken;
    next(context?: LexerContext): IteratorResult<LexerToken, undefined>;
    return(value?: undefined): IteratorResult<LexerToken, undefined>;
    throw(e?: unknown): IteratorResult<LexerToken, undefined>;
    [Symbol.iterator](): Generator<LexerToken, undefined, LexerContext | undefined>;
    peek(context?: LexerContext): IteratorResult<LexerToken, undefined>;
    /** Saves the lexer state to be restored later. */
    save(): [LexerToken, boolean];
    /**
     * Roll back the state of the lexer to the given saved state.
     *
     * The lexer will continue from this state forward.
     */
    rollback(state: [LexerToken, boolean]): void;
    /**
     * Compute start location of the token following `lastToken`.
     */
    private computeNextTokenStartLocation;
    /** Reads the next token following the `afterPosition`. */
    private readNextToken;
}
